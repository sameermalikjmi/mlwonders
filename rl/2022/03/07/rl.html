<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>RL Introduction | MLWonders</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="RL Introduction" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="RL Introduction based on MDP" />
<meta property="og:description" content="RL Introduction based on MDP" />
<link rel="canonical" href="https://sameermalikjmi.github.io/mlwonders/rl/2022/03/07/rl.html" />
<meta property="og:url" content="https://sameermalikjmi.github.io/mlwonders/rl/2022/03/07/rl.html" />
<meta property="og:site_name" content="MLWonders" />
<meta property="og:image" content="https://sameermalikjmi.github.io/mlwonders/images/chart-preview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-07T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://sameermalikjmi.github.io/mlwonders/images/chart-preview.png" />
<meta property="twitter:title" content="RL Introduction" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-03-07T00:00:00-06:00","datePublished":"2022-03-07T00:00:00-06:00","description":"RL Introduction based on MDP","headline":"RL Introduction","image":"https://sameermalikjmi.github.io/mlwonders/images/chart-preview.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://sameermalikjmi.github.io/mlwonders/rl/2022/03/07/rl.html"},"url":"https://sameermalikjmi.github.io/mlwonders/rl/2022/03/07/rl.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/mlwonders/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sameermalikjmi.github.io/mlwonders/feed.xml" title="MLWonders" /><link rel="shortcut icon" type="image/x-icon" href="/mlwonders/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/mlwonders/">MLWonders</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/mlwonders/2020-01-14-test-markdown-post.html">An Example Markdown Post</a><a class="page-link" href="/mlwonders/about/">About Me</a><a class="page-link" href="/mlwonders/search/">Search</a><a class="page-link" href="/mlwonders/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">RL Introduction</h1><p class="page-description">RL Introduction based on MDP</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-03-07T00:00:00-06:00" itemprop="datePublished">
        Mar 7, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/mlwonders/categories/#RL">RL</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/sameermalikjmi/mlwonders/tree/master/_notebooks/2022-03-07-rl.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/mlwonders/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/sameermalikjmi/mlwonders/master?filepath=_notebooks%2F2022-03-07-rl.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/mlwonders/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/sameermalikjmi/mlwonders/blob/master/_notebooks/2022-03-07-rl.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/mlwonders/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fsameermalikjmi%2Fmlwonders%2Fblob%2Fmaster%2F_notebooks%2F2022-03-07-rl.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/mlwonders/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#Reinforcement-Learning">Reinforcement Learning </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Element-of-RL">Element of RL </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Policy">Policy </a></li>
<li class="toc-entry toc-h4"><a href="#Reward">Reward </a></li>
<li class="toc-entry toc-h4"><a href="#Value">Value </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Important">Important </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-03-07-rl.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/mlwonders/images/copied_from_nb/my_icons/rl_logo.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Reinforcement-Learning">
<a class="anchor" href="#Reinforcement-Learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reinforcement Learning<a class="anchor-link" href="#Reinforcement-Learning"> </a>
</h2>
<p>Reinforcement learning is learning what to do—how to map situations to actions—so as to maximize a numerical reward signal. The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them. In
the most interesting and challenging cases, actions may affect not only the immediate reward but also the next situation and, through that, all subsequent rewards. These two characteristics—trial-and-error search and delayed reward—are the two most important
distinguishing features of reinforcement learning. [^1]: Richard and Sutton.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Element-of-RL">
<a class="anchor" href="#Element-of-RL" aria-hidden="true"><span class="octicon octicon-link"></span></a>Element of RL<a class="anchor-link" href="#Element-of-RL"> </a>
</h3>
<h4 id="Policy">
<a class="anchor" href="#Policy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Policy<a class="anchor-link" href="#Policy"> </a>
</h4>
<p>A policy defines the learning agent’s way of behaving at a given time. Roughly speaking,
a policy is a mapping from perceived states of the environment to actions to be taken
when in those states.</p>
<h4 id="Reward">
<a class="anchor" href="#Reward" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reward<a class="anchor-link" href="#Reward"> </a>
</h4>
<p>On each time
step, the environment sends to the reinforcement learning agent a single number called
the reward. The agent’s sole objective is to maximize the total reward it receives over
the long run.</p>
<h4 id="Value">
<a class="anchor" href="#Value" aria-hidden="true"><span class="octicon octicon-link"></span></a>Value<a class="anchor-link" href="#Value"> </a>
</h4>
<p>The value of a state is the total amount of reward an agent can expect to accumulate over the future, starting
from that state. Whereas rewards determine the immediate, intrinsic desirability of
environmental states, values indicate the long-term desirability of states after taking into
account the states that are likely to follow and the rewards available in those states. For
example, a state might always yield a low immediate reward but still have a high value
because it is regularly followed by other states that yield high rewards.</p>
<h2 id="Important">
<a class="anchor" href="#Important" aria-hidden="true"><span class="octicon octicon-link"></span></a>Important<a class="anchor-link" href="#Important"> </a>
</h2>
<p>The central role of value estimation is arguably
the most important thing that has been learned about reinforcement learning over the
last six decades.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">gym.envs.registration</span> <span class="kn">import</span> <span class="n">register</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Evaluate deterministic</span>
<span class="n">register</span><span class="p">(</span>
    <span class="nb">id</span><span class="o">=</span><span class="s1">'Deterministic-4x4-FrozenLake-v0'</span><span class="p">,</span>
    <span class="n">entry_point</span><span class="o">=</span><span class="s1">'gym.envs.toy_text.frozen_lake:FrozenLakeEnv'</span><span class="p">,</span>
    <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">'map_name'</span><span class="p">:</span> <span class="s1">'4x4'</span><span class="p">,</span>
            <span class="s1">'is_slippery'</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">policy_evaluation</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">nS</span><span class="p">,</span> <span class="n">nA</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
    <span class="sd">"""Evaluate the value function from a given policy.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    P, nS, nA, gamma:</span>
<span class="sd">        defined at beginning of file</span>
<span class="sd">    policy: np.array[nS,nA]</span>
<span class="sd">        The policy to evaluate. Maps states to actions.</span>
<span class="sd">    tol: float</span>
<span class="sd">        Terminate policy evaluation when</span>
<span class="sd">            max |value_function(s) - prev_value_function(s)| &lt; tol</span>
<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    value_function: np.ndarray[nS]</span>
<span class="sd">        The value function of the given policy, where value_function[s] is</span>
<span class="sd">        the value of state s</span>
<span class="sd">    """</span>
    
    <span class="n">value_function</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nS</span><span class="p">)</span>
    
  
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
      
        <span class="n">difference</span><span class="o">=</span><span class="mi">0</span>
      
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nS</span><span class="p">):</span>
            <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">action_prob</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">policy</span><span class="p">[</span><span class="n">s</span><span class="p">]):</span>
                
                <span class="k">for</span> <span class="n">probability</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminal</span> <span class="ow">in</span> <span class="n">P</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">]:</span>
                  
                    <span class="nb">sum</span> <span class="o">+=</span> <span class="n">action_prob</span> <span class="o">*</span> <span class="n">probability</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">value_function</span><span class="p">[</span><span class="n">next_state</span><span class="p">])</span>

           
            <span class="n">difference</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">difference</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">value_function</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">-</span><span class="nb">sum</span><span class="p">))</span>

            
            <span class="n">value_function</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span>

       
        <span class="k">if</span> <span class="n">difference</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">value_function</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">"FrozenLake-v1"</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">unwrapped</span>
<span class="n">random_policy2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">env</span><span class="o">.</span><span class="n">nS</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">nA</span><span class="p">])</span> <span class="o">/</span> <span class="n">env</span><span class="o">.</span><span class="n">nA</span>
<span class="n">policy_evaluation</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">P</span><span class="p">,</span><span class="n">env</span><span class="o">.</span><span class="n">nS</span><span class="p">,</span><span class="n">env</span><span class="o">.</span><span class="n">nA</span><span class="p">,</span> <span class="n">random_policy2</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.004, 0.004, 0.01 , 0.004, 0.007, 0.   , 0.026, 0.   , 0.019,
       0.058, 0.107, 0.   , 0.   , 0.13 , 0.391, 0.   ])</pre>
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="sameermalikjmi/mlwonders"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/mlwonders/rl/2022/03/07/rl.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/mlwonders/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/mlwonders/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/mlwonders/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Collection of AI and Robotics topics.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sameermalikjmi" target="_blank" title="sameermalikjmi"><svg class="svg-icon grey"><use xlink:href="/mlwonders/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
